input {
        file {
                'path' => '/logs/apache/*.log'
                'type' => 'apache'
                'start_position' => 'beginning'
        }
        file {
                'path' => '/logs/nginx/*.log'
                'type' => 'nginx'
                'start_position' => 'beginning'
        }
        file {
        		'path' => '/logs/iis/*.log'
                'type' => 'iis'
                'start_position' => 'beginning'
        }

}

filter {
	if [type] == "apache" {
		grok {
		   match => { "message" => "%{COMBINEDAPACHELOG}" }
		}

		date {
	      # Try to pull the timestamp from the 'timestamp' field (parsed above with
	      # grok). The apache time format looks like: "18/Aug/2011:05:44:34 -0700"
	      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
	      locale => 'en'
	    }
	}

	if [type] == "nginx" {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "message" => "%{NGINXACCESS}" }
		}

		date {
	      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
	      locale => 'en'
	    }
	}

	if [type] == "iis" {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "message" => "%{IISLOG}" }
		}

		date {
	      match => [ "timestamp", "YYYY-MM-dd HH:mm:ss" ]
	      locale => 'en'
	    }

	    if ![querystring] or [querystring] == "-" {
		    mutate { 
			  add_field => ["request", "%{page}"] 
			}
	    } else {
		    mutate { 
			  add_field => ["request", "%{page}?%{querystring}"] 
			}
	    } 
	}


	if ![bot] {
	   grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_WEB}" }
		   add_field => { "bot" => "Googlebot Web" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_MOBILE}" }
		   add_field => { "bot" => "Googlebot mobile" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_NEWS}" }
		   add_field => { "bot" => "Googlebot news" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_IMAGE}" }
		   add_field => { "bot" => "Googlebot image" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_VIDEO}" }
		   add_field => { "bot" => "Googlebot video" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "agent" => "%{GOOGLEBOT_MEDIAPARTNERS}" }
		   add_field => { "bot" => "GoogleBot mediapartners" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		grok {
		   match => { "agent" => "Googlebot" }
		   add_field => { "bot" => "other Googlebot" }
		   tag_on_failure => []
		}
	}

	if ![bot] {
		drop {}
	}


	## Per site category
	# By default extract the first path component

	grok {
		   patterns_dir => "/etc/logstash/patterns"
		   match => { "request" => "/%{PATH_COMPONENT:category}/" }
	}

	if ![category] {
		mutate {
			add_field => { "category" => "other" }
		}
	}
	# end per site category

    geoip {
    	source => 'clientip'
    }

    mutate {
	    convert => { 
	    	"response" => "integer"
	    	"bytes" => "integer"
	    }
	}

    fingerprint { key => "OnCrawl" }
}

output { 

	elasticsearch { 
		hosts => ["elasticsearch"]
		document_id => "%{fingerprint}"
		index => "logstash-%{+YYYY.MM}"
	}
#	stdout { codec => rubydebug }
}
